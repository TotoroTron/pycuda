Traceback (most recent call last):
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/errors.py", line 717, in new_error_context
    yield
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/lowering.py", line 288, in lower_block
    self.lower_inst(inst)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/lowering.py", line 360, in lower_inst
    val = self.lower_assign(ty, inst)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/lowering.py", line 534, in lower_assign
    return self.lower_expr(ty, value)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/lowering.py", line 999, in lower_expr
    res = self.lower_call(resty, expr)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/lowering.py", line 791, in lower_call
    res = self._lower_call_normal(fnty, expr, signature)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/lowering.py", line 970, in _lower_call_normal
    res = impl(self.builder, argvals, self.loc)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/targets/base.py", line 1146, in __call__
    res = self._imp(self._context, builder, self._sig, args, loc=loc)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/targets/base.py", line 1176, in wrapper
    return fn(*args, **kwargs)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/cuda/cudaimpl.py", line 174, in ptx_smem_alloc_array
    can_dynsized=True)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/cuda/cudaimpl.py", line 629, in _generic_array
    elemcount = reduce(operator.mul, shape)
TypeError: unsupported operand type(s) for *: 'Macro' and 'Macro'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "main.py", line 84, in <module>
    main()
  File "main.py", line 68, in main
    m.matmul_cudajit_sharedmem[blocks_per_grid, threads_per_block](d_matA, d_matB, d_matC)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/cuda/compiler.py", line 798, in __call__
    kernel = self.specialize(*args)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/cuda/compiler.py", line 809, in specialize
    kernel = self.compile(argtypes)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/cuda/compiler.py", line 825, in compile
    **self.targetoptions)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/compiler_lock.py", line 32, in _acquire_compile_lock
    return func(*args, **kwargs)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/cuda/compiler.py", line 61, in compile_kernel
    cres = compile_cuda(pyfunc, types.void, args, debug=debug, inline=inline)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/compiler_lock.py", line 32, in _acquire_compile_lock
    return func(*args, **kwargs)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/cuda/compiler.py", line 50, in compile_cuda
    locals={})
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/compiler.py", line 551, in compile_extra
    return pipeline.compile_extra(func)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/compiler.py", line 331, in compile_extra
    return self._compile_bytecode()
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/compiler.py", line 393, in _compile_bytecode
    return self._compile_core()
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/compiler.py", line 373, in _compile_core
    raise e
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/compiler.py", line 364, in _compile_core
    pm.run(self.state)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/compiler_machinery.py", line 347, in run
    raise patched_exception
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/compiler_machinery.py", line 338, in run
    self._runPass(idx, pass_inst, state)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/compiler_lock.py", line 32, in _acquire_compile_lock
    return func(*args, **kwargs)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/compiler_machinery.py", line 302, in _runPass
    mutated |= check(pss.run_pass, internal_state)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/compiler_machinery.py", line 275, in check
    mangled = func(compiler_state)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/typed_passes.py", line 407, in run_pass
    NativeLowering().run_pass(state)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/typed_passes.py", line 349, in run_pass
    lower.lower()
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/lowering.py", line 195, in lower
    self.lower_normal_function(self.fndesc)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/lowering.py", line 248, in lower_normal_function
    entry_block_tail = self.lower_function_body()
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/lowering.py", line 273, in lower_function_body
    self.lower_block(block)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/lowering.py", line 288, in lower_block
    self.lower_inst(inst)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/errors.py", line 725, in new_error_context
    six.reraise(type(newerr), newerr, tb)
  File "/home/bbc33/anaconda3/envs/pycuda/lib/python3.6/site-packages/numba/six.py", line 669, in reraise
    raise value
numba.errors.LoweringError: Failed in nopython mode pipeline (step: nopython mode backend)
unsupported operand type(s) for *: 'Macro' and 'Macro'

File "matmul.py", line 71:
def matmul_cudajit_sharedmem(A, B, C):
    <source elided>
    # The size and type of the arrays must be known at compile time.  
    sA = cuda.shared.array(shape=(TPB, TPB), dtype=float32)
    ^

[1] During: lowering "$0.12 = call ptx.smem.alloc(func=ptx.smem.alloc, args=[], kws=[('shape', Var($0.9, matmul.py:71)), ('dtype', Var($0.10, matmul.py:71))], vararg=None)" at /scratch/bbc33/pycuda/cuda/ex2/matmul.py (71)
